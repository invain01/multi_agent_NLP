{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 332,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06042296072507553,
      "grad_norm": 1.065854787826538,
      "learning_rate": 4.5e-05,
      "loss": 3.141,
      "step": 10
    },
    {
      "epoch": 0.12084592145015106,
      "grad_norm": 1.0974820852279663,
      "learning_rate": 4.860248447204969e-05,
      "loss": 2.8765,
      "step": 20
    },
    {
      "epoch": 0.18126888217522658,
      "grad_norm": 1.1899198293685913,
      "learning_rate": 4.7049689440993793e-05,
      "loss": 2.5921,
      "step": 30
    },
    {
      "epoch": 0.24169184290030213,
      "grad_norm": 1.0147284269332886,
      "learning_rate": 4.549689440993789e-05,
      "loss": 2.3006,
      "step": 40
    },
    {
      "epoch": 0.3021148036253776,
      "grad_norm": 0.9531290531158447,
      "learning_rate": 4.3944099378881993e-05,
      "loss": 2.2528,
      "step": 50
    },
    {
      "epoch": 0.36253776435045315,
      "grad_norm": 1.1597025394439697,
      "learning_rate": 4.239130434782609e-05,
      "loss": 2.3096,
      "step": 60
    },
    {
      "epoch": 0.4229607250755287,
      "grad_norm": 0.9988191723823547,
      "learning_rate": 4.0838509316770193e-05,
      "loss": 2.1536,
      "step": 70
    },
    {
      "epoch": 0.48338368580060426,
      "grad_norm": 1.1791037321090698,
      "learning_rate": 3.928571428571429e-05,
      "loss": 2.0084,
      "step": 80
    },
    {
      "epoch": 0.5438066465256798,
      "grad_norm": 1.1432454586029053,
      "learning_rate": 3.773291925465839e-05,
      "loss": 1.9953,
      "step": 90
    },
    {
      "epoch": 0.6042296072507553,
      "grad_norm": 1.3588918447494507,
      "learning_rate": 3.618012422360248e-05,
      "loss": 2.0359,
      "step": 100
    },
    {
      "epoch": 0.6646525679758308,
      "grad_norm": 1.2848727703094482,
      "learning_rate": 3.462732919254659e-05,
      "loss": 2.1299,
      "step": 110
    },
    {
      "epoch": 0.7250755287009063,
      "grad_norm": 1.4115201234817505,
      "learning_rate": 3.307453416149068e-05,
      "loss": 2.0264,
      "step": 120
    },
    {
      "epoch": 0.7854984894259819,
      "grad_norm": 1.5307773351669312,
      "learning_rate": 3.152173913043479e-05,
      "loss": 1.9747,
      "step": 130
    },
    {
      "epoch": 0.8459214501510574,
      "grad_norm": 1.608784556388855,
      "learning_rate": 2.9968944099378883e-05,
      "loss": 1.9728,
      "step": 140
    },
    {
      "epoch": 0.9063444108761329,
      "grad_norm": 1.5702135562896729,
      "learning_rate": 2.8416149068322983e-05,
      "loss": 2.0081,
      "step": 150
    },
    {
      "epoch": 0.9667673716012085,
      "grad_norm": 1.4231668710708618,
      "learning_rate": 2.686335403726708e-05,
      "loss": 2.1196,
      "step": 160
    },
    {
      "epoch": 1.0241691842900302,
      "grad_norm": 1.476460337638855,
      "learning_rate": 2.5310559006211183e-05,
      "loss": 1.8931,
      "step": 170
    },
    {
      "epoch": 1.0845921450151057,
      "grad_norm": 1.5386875867843628,
      "learning_rate": 2.375776397515528e-05,
      "loss": 1.8963,
      "step": 180
    },
    {
      "epoch": 1.1450151057401814,
      "grad_norm": 1.6359363794326782,
      "learning_rate": 2.220496894409938e-05,
      "loss": 1.901,
      "step": 190
    },
    {
      "epoch": 1.2054380664652569,
      "grad_norm": 1.6538026332855225,
      "learning_rate": 2.065217391304348e-05,
      "loss": 1.9046,
      "step": 200
    },
    {
      "epoch": 1.2658610271903323,
      "grad_norm": 1.544670581817627,
      "learning_rate": 1.909937888198758e-05,
      "loss": 1.7963,
      "step": 210
    },
    {
      "epoch": 1.3262839879154078,
      "grad_norm": 1.3794711828231812,
      "learning_rate": 1.7546583850931676e-05,
      "loss": 1.9057,
      "step": 220
    },
    {
      "epoch": 1.3867069486404833,
      "grad_norm": 1.9392578601837158,
      "learning_rate": 1.5993788819875776e-05,
      "loss": 1.8751,
      "step": 230
    },
    {
      "epoch": 1.447129909365559,
      "grad_norm": 1.4577927589416504,
      "learning_rate": 1.4440993788819876e-05,
      "loss": 1.8867,
      "step": 240
    },
    {
      "epoch": 1.5075528700906344,
      "grad_norm": 1.8727163076400757,
      "learning_rate": 1.2888198757763975e-05,
      "loss": 1.9528,
      "step": 250
    },
    {
      "epoch": 1.5679758308157101,
      "grad_norm": 1.5641919374465942,
      "learning_rate": 1.1335403726708076e-05,
      "loss": 1.9803,
      "step": 260
    },
    {
      "epoch": 1.6283987915407856,
      "grad_norm": 1.5899041891098022,
      "learning_rate": 9.782608695652175e-06,
      "loss": 2.0862,
      "step": 270
    },
    {
      "epoch": 1.688821752265861,
      "grad_norm": 1.8195579051971436,
      "learning_rate": 8.229813664596275e-06,
      "loss": 1.6888,
      "step": 280
    },
    {
      "epoch": 1.7492447129909365,
      "grad_norm": 1.4933358430862427,
      "learning_rate": 6.677018633540373e-06,
      "loss": 1.7123,
      "step": 290
    },
    {
      "epoch": 1.809667673716012,
      "grad_norm": 1.777586579322815,
      "learning_rate": 5.124223602484472e-06,
      "loss": 1.8891,
      "step": 300
    },
    {
      "epoch": 1.8700906344410875,
      "grad_norm": 1.6980953216552734,
      "learning_rate": 3.5714285714285714e-06,
      "loss": 1.8117,
      "step": 310
    },
    {
      "epoch": 1.9305135951661632,
      "grad_norm": 1.636785626411438,
      "learning_rate": 2.018633540372671e-06,
      "loss": 1.9194,
      "step": 320
    },
    {
      "epoch": 1.9909365558912386,
      "grad_norm": 1.6640115976333618,
      "learning_rate": 4.6583850931677024e-07,
      "loss": 2.0163,
      "step": 330
    }
  ],
  "logging_steps": 10,
  "max_steps": 332,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4322755261243392.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
