# ====================================================================
# 多智能体学术写作优化系统 - 环境变量配置示例
# ====================================================================
# 复制此文件为 .env 并根据实际情况修改配置值

# ====================================================================
# API 配置
# ====================================================================
# OpenAI API Key (教师模型)
OPENAI_API_KEY=

# OpenAI Base URL (可选，用于自定义 API 端点)
OPENAI_BASE_URL=https://api.deepseek.com

# LLM 模型名称
LLM_MODEL=deepseek-reasoner

# SerpAPI Key (可选，用于网络搜索工具)
SERPAPI_API_KEY=

# Embedding 模型名称
EMBED_MODEL_NAME=text-embedding-3-small

# ====================================================================
# 学生模型配置（本地模型）
# ====================================================================
# 学生模型基础模型路径或 HuggingFace 模型名
# 推荐: Qwen/Qwen1.5-1.8B-Chat 或 Qwen/Qwen2-1.5B-Instruct
# 也可以使用本地路径，例如: D:/Projects/NLP/models/Qwen1.5-1.8B-Chat
STUDENT_BASE_MODEL=Qwen/Qwen1.5-1.8B-Chat

# LoRA 适配器目录（可选）
# 例如: D:/Projects/NLP/multi_agent_NLP/runs/qwen1_8b_final__v2
STUDENT_LORA_DIR=

# 生成最大 Token 数
STUDENT_MAX_NEW_TOKENS=64

# ====================================================================
# 内存优化配置 - 重要！解决内存占用过高问题
# ====================================================================
# 是否启用 4bit 量化（推荐启用以节省内存）
# 1 = 启用（内存占用约 1-2GB），0 = 禁用（内存占用约 6-8GB）
STUDENT_LOAD_IN_4BIT=1

# 是否强制使用 CPU 运行学生模型（适用于显存不足的情况）
# 1 = 使用 CPU（更慢但节省显存），0 = 使用 GPU（更快）
STUDENT_FORCE_CPU=0

# ====================================================================
# 混合模式配置
# ====================================================================
# 是否启用混合模式（学生模型 + 教师模型）
# 1 = 启用混合模式，0 = 仅使用教师模型
ENABLE_HYBRID=1

# 测试/CI 强制使用学生模型占位而不下载真实权重
# 1 = 启用 Stub 模式，0 = 正常加载模型
FORCE_STUDENT_STUB=0

# 交互模式（CLI 中启用实时）
ENABLE_INTERACTIVE=0

# ====================================================================
# 推荐配置方案
# ====================================================================
# 
# 【低内存方案】（内存 < 8GB 或 Web 应用频繁崩溃）
# STUDENT_LOAD_IN_4BIT=1
# STUDENT_FORCE_CPU=1
# ENABLE_HYBRID=1
#
# 【标准方案】（内存 8-16GB，有 GPU）
# STUDENT_LOAD_IN_4BIT=1
# STUDENT_FORCE_CPU=0
# ENABLE_HYBRID=1
#
# 【高性能方案】（内存 > 16GB，有 GPU）
# STUDENT_LOAD_IN_4BIT=0
# STUDENT_FORCE_CPU=0
# ENABLE_HYBRID=1
#
# 【仅教师模型】（不使用本地模型，内存占用最低）
# ENABLE_HYBRID=0
#
# 【测试模式】（不加载真实模型，快速测试）
# FORCE_STUDENT_STUB=1
# ====================================================================


